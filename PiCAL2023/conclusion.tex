This paper proposes a modeling language that integrates privacy features into core $\pi $ calculus and explores how syntax and semantics can be used to ensure personal data handling by design and default. The motivation behind incorporating privacy constructs, along with existing challenges in the field, is explored, emphasizing their integration into calculus for enforcing consent-based data processing. Operational semantics, offering such abstractions, are presented, and an evaluation is conducted through a healthcare example and a Maude-based simulation environment that allows us to simulate programs and experiment with our new calculus features. Our currently proposed semantics are fixed to a concrete interpretation of GDPR terminology. Exploring how to parametrize the transition rules concerning desired personal data handling checks according to different data privacy legislations and domain expertise would be interesting. The proposed data privacy checks introduce notable runtime overheads for every transition rule handling data, prompting future investigation into reducing checkpoints while still ensuring compliance. Techniques like behavioral types ~\cite{BehaviouralTypes2016} could be explored to statically approximate the required checks and offer a type system for the calculus. To demonstrate correctness, the paper aims to prove bisimulation equivalence for systems.